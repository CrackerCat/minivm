
#include "jit.h"
#include "../build.h"
#include "../../int/gc.h"

#include "../../../luajit/dynasm/dasm_proto.h"
#include "../../../luajit/dynasm/dasm_x86.h"

#if _WIN32
#include <stdio.h>
#include <Windows.h>
#else
#include <sys/mman.h>
#if !defined(MAP_ANONYMOUS) && defined(MAP_ANON)
#define MAP_ANONYMOUS MAP_ANON
#endif
#endif

#define VM_REG_MAX (7)
#define VM_REG_OFFSET(n) (n == 0 ? 1 : n+9)
#define VM_STACK_OFFSET(n) (((n)-VM_REG_MAX) * 8)

void vm_ir_be_jit_putc(int n)
{
    fprintf(stdout, "%c", n);
}

ptrdiff_t vm_ir_be_jit_len(vm_gc_t *gc, ptrdiff_t ptr)
{
    return gc->buf[(ptr << 1) - 1].header.len << 1;
}

ptrdiff_t vm_ir_be_jit_alloc(vm_gc_t *gc, ptrdiff_t ptr)
{
    return (vm_gc_arr(gc, ptr >> 1) << 1) | 1;
}

ptrdiff_t vm_ir_be_jit_get(vm_gc_t *gc, ptrdiff_t ptr, ptrdiff_t nth)
{
    return gc->buf[(ptr + nth) >> 1].value.ival;
}

void vm_ir_be_jit_set(vm_gc_t *gc, ptrdiff_t ptr, ptrdiff_t nth, ptrdiff_t val)
{
    gc->buf[(ptr + nth) >> 1].value.ival = val;
}

size_t vm_ir_be_jit_arg_reg(size_t n)
{
    size_t args[] = {
        7,
        6,
        3,
        2,
        8,
        9,
    };
    return args[n];
}

|.arch x64

#define VM_WIN 0
|.if WIN
|.define vmArg1, rcx
|.define vmArg2, rdx
|.define vmArg3, r8
|.define vmArg4, r9
|.else
|.define vmRegTmp1, rbx
|.define vmArg1, rdi
|.define vmArg2, rsi
|.define vmArg3, rdx
|.define vmArg4, rcx
|.endif

|.macro pusha
| push rcx
| push rbp
| push vmArg1
| push vmArg2
| push vmArg3
| push vmArg4
| push vmRegTmp1
| push r10
| push r11
| push r12
| push r13
| push r14
| push r15
|.endmacro

|.macro popa
| pop r15
| pop r14
| pop r13
| pop r12
| pop r11
| pop r10
| pop vmRegTmp1
| pop vmArg4
| pop vmArg3
| pop vmArg2
| pop vmArg1
| pop rbp
| pop rcx
|.endmacro

|.macro vmCall, x64reg
| pusha
| call x64reg
| popa
|.endmacro

|.macro vmPrintDyn, x64reg
| pusha
| mov vmArg2, x64reg
| xor eax, eax
| mov64 vmRegTmp1, (size_t) &printf
| mov64 vmArg1, (size_t) "[%zu]"
| vmCall vmRegTmp1
| popa
|.endmacro

|.macro vmLoad, x64reg, vmReg
|| if (vmReg < VM_REG_MAX)
|| {
    | mov x64reg, Rq(VM_REG_OFFSET(vmReg))
|| }
|| else
|| {
    | mov x64reg, [rsp + VM_STACK_OFFSET(vmReg)]
|| }
|.endmacro

|.macro vmStore, vmReg, x64reg
|| if (vmReg < VM_REG_MAX)
|| {
    | mov Rq(VM_REG_OFFSET(vmReg)), x64reg
|| }
|| else
|| {
    | mov [rsp + VM_STACK_OFFSET(vmReg)], x64reg
|| }
|.endmacro

|.macro vmLoadArg, x64reg, arg
||do
||{
||vm_ir_arg_t *arg_ = (arg);
||switch (arg_->type)
||{
||case VM_IR_ARG_FUNC:
||{
    |lea x64reg, [=>arg_->func->id*2]
    ||break;
||}
||case VM_IR_ARG_REG:
||{
    |vmLoad x64reg, arg_->reg
    ||break;
||}
||case VM_IR_ARG_NUM:
||{
    |mov64 x64reg, arg_->num * 2
    ||break;
||}
||}
||} while (0);
|.endmacro

|.macro vmPrintNum, index
||do
||{
    | pusha
    | xor eax, eax
    | mov vmArg2, index
    | mov64 vmRegTmp1, (size_t) &printf
    | mov64 vmArg1, (size_t) "%zi"
    | vmCall vmRegTmp1
    | popa
||} while (0);
|.endmacro

|.macro vmPrintStr, str
||do
||{
    | pusha
    ||const char *str_ = str;
    ||while (*str_)
    ||{
        | mov vmArg1, (size_t) *str_
        | mov64 vmRegTmp1, (size_t) &vm_ir_be_jit_putc 
        | call vmRegTmp1
        ||str_+=1;
    ||}
    | popa
||} while (0);
|.endmacro

static void *link_and_encode(dasm_State **d, size_t *sz)
{
    void* buf;
    dasm_link(d, sz);
#if VM_WIN
    buf = VirtualAlloc(0, *sz, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE);
#else
    buf = mmap(0, *sz, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
#endif
    dasm_encode(d, buf);
#if VM_WIN
    {DWORD dwOld; VirtualProtect(buf, *sz, PAGE_EXECUTE_READ, &dwOld); }
#else
    mprotect(buf, *sz, PROT_READ | PROT_EXEC);
#endif
    return buf;
}

void vm_ir_be_jit_block(dasm_State **Dst, vm_gc_t *gc, size_t *store, vm_ir_block_t *block)
{
    for (size_t ninstr = 0; ninstr < block->len; ninstr++)
    {
        vm_ir_instr_t *instr = block->instrs[ninstr];
        switch (instr->op)
        {
        case VM_IR_IOP_NOP:
        {
            break;
        }
        case VM_IR_IOP_MOVE:
        {
            | vmLoadArg vmRegTmp1, instr->args[0]
            | vmStore instr->out->reg, vmRegTmp1
            break;
        }
        case VM_IR_IOP_ADD:
        {
            | vmLoadArg vmRegTmp1, instr->args[0]
            if (instr->args[1]->type == VM_IR_ARG_REG)
            {
                if (instr->args[1]->reg < VM_REG_MAX)
                {
                    | add vmRegTmp1, Rq(VM_REG_OFFSET(instr->args[1]->reg))
                }
                else
                {
                    | add vmRegTmp1, [rsp + VM_STACK_OFFSET(instr->args[1]->reg)]
                }
            }
            else if (instr->args[1]->type == VM_IR_ARG_NUM)
            {
                | add vmRegTmp1, instr->args[1]->num * 2
            }
            else
            {
                __builtin_trap();
            }
            | vmStore instr->out->reg, vmRegTmp1
            break;
        }
        case VM_IR_IOP_SUB:
        {
            | vmLoadArg vmRegTmp1, instr->args[0]
            if (instr->args[1]->type == VM_IR_ARG_REG)
            {
                if (instr->args[1]->reg < VM_REG_MAX)
                {
                    | sub vmRegTmp1, Rq(VM_REG_OFFSET(instr->args[1]->reg))
                }
                else
                {
                    | sub vmRegTmp1, [rsp + VM_STACK_OFFSET(instr->args[1]->reg)]
                }
            }
            else if (instr->args[1]->type == VM_IR_ARG_NUM)
            {
                | sub vmRegTmp1, instr->args[1]->num * 2
            }
            else
            {
                __builtin_trap();
            }
            | vmStore instr->out->reg, vmRegTmp1
            break;
        }
        case VM_IR_IOP_MUL:
        {
            | vmLoadArg rax, instr->args[0]
            | vmLoadArg vmRegTmp1, instr->args[1]
            | imul vmRegTmp1
            | shr rax, 1
            | vmStore instr->out->reg, rax
            break;
        }
        case VM_IR_IOP_DIV:
        {
            | xor edx, edx
            | vmLoadArg rax, instr->args[0]
            | vmLoadArg vmRegTmp1, instr->args[1]
            | idiv vmRegTmp1
            | shl rax, 1
            | vmStore instr->out->reg, rax
            break;
        }
        case VM_IR_IOP_MOD:
        {
            | xor edx, edx
            | vmLoadArg rax, instr->args[0]
            | vmLoadArg vmRegTmp1, instr->args[1]
            | idiv vmRegTmp1
            | vmStore instr->out->reg, rdx
            break;
        }
        case VM_IR_IOP_CALL:
        {
            for (size_t arg = 1; instr->args[arg]; arg++)
            {
                | vmLoadArg Rq(vm_ir_be_jit_arg_reg(arg-1)), instr->args[arg]
            }
            uint8_t saved[8] = {0};
            {
                if (instr->out != NULL && instr->out->type == VM_IR_ARG_REG && instr->out->reg < 8 && saved[instr->out->reg] == 0)
                {
                    saved[instr->out->reg] = 1;
                }
                for (size_t seek = ninstr+1; seek < block->len; seek++)
                {
                    vm_ir_instr_t *instr = block->instrs[seek];
                    for (size_t j = 0; instr->args[j] != NULL; j++)
                    {
                        vm_ir_arg_t *arg = instr->args[j];
                        if (arg->type == VM_IR_ARG_REG && arg->reg < 8 && saved[arg->reg] == 0)
                        {
                            saved[arg->reg] = 2;
                        }
                    }
                    if (instr->out != NULL && instr->out->type == VM_IR_ARG_REG && instr->out->reg < 8 && saved[instr->out->reg] == 0)
                    {
                        saved[instr->out->reg] = 1;
                    }
                }
                for (size_t j = 0; j < 2; j++)
                {
                    vm_ir_arg_t *arg = block->branch->args[j];
                    if (arg == NULL)
                    {
                        continue;
                    }
                    if (arg->type == VM_IR_ARG_REG && arg->reg < 8 && saved[arg->reg] == 0)
                    {
                        saved[arg->reg] = 2;
                    }
                }
                for (size_t j = 0; j < 2; j++)
                {
                    vm_ir_block_t *target = block->branch->targets[j];
                    if (target == NULL)
                    {
                        continue;
                    }
                    for (size_t k = 0; k < target->nargs; k++)
                    {
                        size_t arg = target->args[k];
                        if (arg < 8 && saved[arg] == 0)
                        {
                            saved[arg] = 2;
                        }
                    }
                }
            }
            if (instr->args[0]->type == VM_IR_ARG_REG)
            {
                | vmLoad rax, instr->args[0]->reg
            }
            for (size_t i = 0; i < VM_REG_MAX; i++)
            {
                if (saved[i] == 2)
                {
                    | push Rq(VM_REG_OFFSET(i))
                }
            }
            if (instr->args[0]->type == VM_IR_ARG_REG)
            {
                | call rax
            }
            else if (instr->args[0]->type == VM_IR_ARG_FUNC)
            {
                | call =>instr->args[0]->func->id*2
            }
            else
            {
                __builtin_trap();
            }
            for (ptrdiff_t i = VM_REG_MAX-1; i >= 0; i--)
            {
                if (saved[i] == 2)
                {
                    | pop Rq(VM_REG_OFFSET(i))
                }
            }
            if (instr->out != NULL && instr->out->type == VM_IR_ARG_REG)
            {
                | vmStore instr->out->reg, rax
            }
            break;
        }
        case VM_IR_IOP_ARR:
        {
            | mov64 vmArg1, (size_t) gc
            | vmLoadArg vmArg2, instr->args[0]
            | mov64 vmRegTmp1, (size_t) &vm_ir_be_jit_alloc
            | vmCall vmRegTmp1
            | vmStore instr->out->reg, rax
            break;
        }
        case VM_IR_IOP_GET:
        {
            | mov64 vmArg1, (size_t) gc
            | vmLoadArg vmArg2, instr->args[0]
            | vmLoadArg vmArg3, instr->args[1]
            | mov64 vmRegTmp1, (size_t) &vm_ir_be_jit_get
            | vmCall vmRegTmp1
            | vmStore instr->out->reg, rax
            break;
        }
        case VM_IR_IOP_SET:
        {
            | mov64 vmArg1, (size_t) gc
            | vmLoadArg vmArg2, instr->args[0]
            | vmLoadArg vmArg3, instr->args[1]
            | vmLoadArg vmArg4, instr->args[2]
            | mov64 vmRegTmp1, (size_t) &vm_ir_be_jit_set
            | vmCall vmRegTmp1
            break;
        }
        case VM_IR_IOP_LEN:
        {
            | mov64 vmArg1, (size_t) gc
            | vmLoadArg vmArg2, instr->args[0]
            | mov64 vmRegTmp1, (size_t) &vm_ir_be_jit_len
            | vmCall vmRegTmp1
            | vmStore instr->out->reg, rax
            break;
        }
        case VM_IR_IOP_TYPE:
        {
            |vmPrintStr "error: type\n"
            break;
        }
        case VM_IR_IOP_OUT:
        {
            | vmLoadArg vmArg1, instr->args[0]
            | shr vmArg1, 1
            | mov64 vmRegTmp1, (size_t) &vm_ir_be_jit_putc
            | vmCall vmRegTmp1
            break;
        }
        }
    }
    switch (block->branch->op)
    {
    case VM_IR_BOP_JUMP:
    {
        for (ptrdiff_t i = 0; i < block->branch->targets[0]->nargs; i++)
        {
            | vmLoadArg vmRegTmp1, block->branch->pass[0][i]
            | push vmRegTmp1
        }
        for (ptrdiff_t i = block->branch->targets[0]->nargs-1; i >= 0; i--)
        {
            | pop vmRegTmp1
            | vmStore block->branch->targets[0]->args[i], vmRegTmp1
        }
        | jmp =>block->branch->targets[0]->id*2+1;
        break;
    }
    case VM_IR_BOP_BOOL:
    {
        | vmLoadArg vmRegTmp1, block->branch->args[0]
        | sar vmRegTmp1, 1
        | test vmRegTmp1, vmRegTmp1
        | jnz >1
        for (ptrdiff_t i = 0; i < block->branch->targets[0]->nargs; i++)
        {
            if (block->branch->pass[0][i]->type == VM_IR_ARG_REG && block->branch->pass[0][i]->reg != block->branch->targets[0]->args[i])
            {
                | vmLoadArg vmRegTmp1, block->branch->pass[0][i]
                | push vmRegTmp1
            }
        }
        for (ptrdiff_t i = block->branch->targets[0]->nargs-1; i >= 0; i--)
        {
            if (block->branch->pass[0][i]->type == VM_IR_ARG_REG && block->branch->pass[0][i]->reg != block->branch->targets[0]->args[i])
            {
                | pop vmRegTmp1
                | vmStore block->branch->targets[0]->args[i], vmRegTmp1
            }
        }
        | jmp =>block->branch->targets[0]->id*2+1
        |1:
        for (ptrdiff_t i = 0; i < block->branch->targets[1]->nargs; i++)
        {
            if (block->branch->pass[1][i]->type == VM_IR_ARG_REG && block->branch->pass[1][i]->reg != block->branch->targets[1]->args[i])
            {
                | vmLoadArg vmRegTmp1, block->branch->pass[1][i]
                | push vmRegTmp1
            }
        }
        for (ptrdiff_t i = block->branch->targets[1]->nargs-1; i >= 0; i--)
        {
            if (block->branch->pass[1][i]->type == VM_IR_ARG_REG && block->branch->pass[1][i]->reg != block->branch->targets[1]->args[i])
            {
                | pop vmRegTmp1
                | vmStore block->branch->targets[1]->args[i], vmRegTmp1
            }
        }
        | jmp =>block->branch->targets[1]->id*2+1
        break;
    }
    case VM_IR_BOP_LESS:
    {
        | vmLoadArg vmRegTmp1, block->branch->args[0]
        if (block->branch->args[1]->type == VM_IR_ARG_REG)
        {
            if (block->branch->args[1]->reg < VM_REG_MAX)
            {
                | cmp vmRegTmp1, Rq(VM_REG_OFFSET(block->branch->args[1]->reg))
            }
            else
            {
                | cmp vmRegTmp1, [rsp + VM_STACK_OFFSET(block->branch->args[1]->reg)]
            }
        }
        else if (block->branch->args[1]->type == VM_IR_ARG_NUM)
        {
            | cmp vmRegTmp1, block->branch->args[1]->num * 2
        }
        else
        {
            __builtin_trap();
        }
        | jl >1
        for (ptrdiff_t i = 0; i < block->branch->targets[0]->nargs; i++)
        {
            if (block->branch->pass[0][i]->type == VM_IR_ARG_REG && block->branch->pass[0][i]->reg != block->branch->targets[0]->args[i])
            {
                | vmLoadArg vmRegTmp1, block->branch->pass[0][i]
                | push vmRegTmp1
            }
        }
        for (ptrdiff_t i = block->branch->targets[0]->nargs-1; i >= 0; i--)
        {
            if (block->branch->pass[0][i]->type == VM_IR_ARG_REG && block->branch->pass[0][i]->reg != block->branch->targets[0]->args[i])
            {
                | pop vmRegTmp1
                | vmStore block->branch->targets[0]->args[i], vmRegTmp1
            }
        }
        | jmp =>block->branch->targets[0]->id*2+1
        |1:
        for (ptrdiff_t i = 0; i < block->branch->targets[1]->nargs; i++)
        {
            if (block->branch->pass[1][i]->type == VM_IR_ARG_REG && block->branch->pass[1][i]->reg != block->branch->targets[1]->args[i])
            {
                | vmLoadArg vmRegTmp1, block->branch->pass[1][i]
                | push vmRegTmp1
            }
        }
        for (ptrdiff_t i = block->branch->targets[1]->nargs-1; i >= 0; i--)
        {
            if (block->branch->pass[1][i]->type == VM_IR_ARG_REG && block->branch->pass[1][i]->reg != block->branch->targets[1]->args[i])
            {
                | pop vmRegTmp1
                | vmStore block->branch->targets[1]->args[i], vmRegTmp1
            }
        }
        | jmp =>block->branch->targets[1]->id*2+1
        break;
    }
    case VM_IR_BOP_EQUAL:
    {
        | vmLoadArg vmRegTmp1, block->branch->args[0]
        if (block->branch->args[1]->type == VM_IR_ARG_REG)
        {
            if (block->branch->args[1]->reg < VM_REG_MAX)
            {
                | cmp vmRegTmp1, Rq(VM_REG_OFFSET(block->branch->args[1]->reg))
            }
            else
            {
                | cmp vmRegTmp1, [rsp + VM_STACK_OFFSET(block->branch->args[1]->reg)]
            }
        }
        else if (block->branch->args[1]->type == VM_IR_ARG_NUM)
        {
            | cmp vmRegTmp1, block->branch->args[1]->num * 2
        }
        else
        {
            __builtin_trap();
        }
        | je >1
        for (ptrdiff_t i = 0; i < block->branch->targets[0]->nargs; i++)
        {
            if (block->branch->pass[0][i]->type == VM_IR_ARG_REG && block->branch->pass[0][i]->reg != block->branch->targets[0]->args[i])
            {
                | vmLoadArg vmRegTmp1, block->branch->pass[0][i]
                | push vmRegTmp1
            }
        }
        for (ptrdiff_t i = block->branch->targets[0]->nargs-1; i >= 0; i--)
        {
            if (block->branch->pass[0][i]->type == VM_IR_ARG_REG && block->branch->pass[0][i]->reg != block->branch->targets[0]->args[i])
            {
                | pop vmRegTmp1
                | vmStore block->branch->targets[0]->args[i], vmRegTmp1
            }
        }
        | jmp =>block->branch->targets[0]->id*2+1
        |1:
        for (ptrdiff_t i = 0; i < block->branch->targets[1]->nargs; i++)
        {
            if (block->branch->pass[1][i]->type == VM_IR_ARG_REG && block->branch->pass[1][i]->reg != block->branch->targets[1]->args[i])
            {
                | vmLoadArg vmRegTmp1, block->branch->pass[1][i]
                | push vmRegTmp1
            }
        }
        for (ptrdiff_t i = block->branch->targets[1]->nargs-1; i >= 0; i--)
        {
            if (block->branch->pass[1][i]->type == VM_IR_ARG_REG && block->branch->pass[1][i]->reg != block->branch->targets[1]->args[i])
            {
                | pop vmRegTmp1
                | vmStore block->branch->targets[1]->args[i], vmRegTmp1
            }
        }
        | jmp =>block->branch->targets[1]->id*2+1
        break;
    }
    case VM_IR_BOP_RET:
    {
        | vmLoadArg rax, block->branch->args[0]
        | mov rsp, rbp
        | pop rbp
        | ret
        break;
    }
    case VM_IR_BOP_EXIT:
    {
        | mov64 rax, (size_t) store
        | mov rsp, [rax]
        | popa
        | ret
        break;
    }
    }
}

void vm_ir_be_jit(size_t nops, vm_ir_block_t *blocks)
{
    vm_gc_t gc;
    size_t nregs = 0;
    vm_gc_init(&gc);
    dasm_State *d;
    dasm_State **Dst = &d;
    |.section code
    dasm_init(Dst, DASM_MAXSECTION);
    |.globals lbl_
    void *labels[lbl__MAX];
    dasm_setupglobal(Dst, labels, lbl__MAX);
    |.actionlist bf_actions
    dasm_setup(Dst, bf_actions);
    dasm_growpc(Dst, nops*2+1);
    size_t out;
    |.code
    |->entry:
    | pusha
    | mov64 rax, (size_t) &out
    | mov [rax], rsp
    | call =>0
    | mov64 rax, (size_t) &out
    | mov rsp, [rax]
    | popa
    | ret
    for (size_t index = 0; index < nops; index++)
    {
        vm_ir_block_t *block = &blocks[index];
        if (block->id != index)
        {
            continue;
        }
        if (block->isfunc || index == 0)
        {
            nregs = block->nregs+1;
            |=>index*2:
            | push rbp
            | mov rbp, rsp
            if (nregs > VM_REG_MAX)
            {
                | sub rsp, (nregs-VM_REG_MAX) * sizeof(ptrdiff_t)
            }
            for (size_t i = 0; i < block->nargs; i++)
            {
                | vmStore block->args[i], Rq(vm_ir_be_jit_arg_reg(i))
            }
        }
        |=>index*2+1:
        vm_ir_be_jit_block(Dst, &gc, &out, block);
    }
    size_t sz = 0;
    void *map = link_and_encode(Dst, &sz);
    dasm_free(Dst);
    void (*fn)(void) = labels[lbl_entry];
    fn();
#if VM_WIN
    VirtualFree(map, sz, MEM_RELEASE);
#else
    munmap(map, sz);
#endif
}
